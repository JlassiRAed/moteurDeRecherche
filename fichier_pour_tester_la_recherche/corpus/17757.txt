A Markov chain is a Mathematical model model of some Stochastic process random process that happens over time Markov chains are called that way because they follow a rule called the Markov property The Markov property says that whatever happens next in a process only depends on how it is right now It doesn t have a memory of how it was before It is helpful to think of a Markov chain as evolving through discrete steps in time although the step doesn t need to have anything to do with time Markov chains can be Discrete time and continuous time discrete or Discrete time and continuous time continuous Discrete Time Markov Chains are split up into discrete time steps like t t t and so on The probability that a chain will go from one state to another state depends only on the state that it s in right now Continuous Time Markov Chains are chains where the time spent in each state is a real number The amount of time the chain stays in a certain state is randomly picked from an exponential distribution which basically means there s an average time a chain will stay in some state plus or minus some random variation An example of a Markov chain are the dietary habits of a creature who only eats grapes cheese or lettuce and whose dietary habits conform to the following rules This creature s eating habits can be modeled with a Markov chain since its choice depends on what it ate yesterday not additionally on what it ate or days ago One statistical property one could calculate is the expected percentage of the time the creature will eat cheese over a long period 